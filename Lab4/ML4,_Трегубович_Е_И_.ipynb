{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hGClrhQA9SAk"
      },
      "source": [
        "# Деревья решений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veekMy8WRjBi"
      },
      "source": [
        "## Построение дерева"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYkVwAFiUHXj"
      },
      "source": [
        "Опишем жадный алгоритм построения бинарного дерева решений:\n",
        "1. Начинаем со всей обучающей выборки $X$, которую помещаем в корень $R_1$.\n",
        "2. Задаём функционал качества $Q(X, j, t)$ и критерий остановки.\n",
        "3. Запускаем построение из корня: $SplitNode(1, R_1)$\n",
        "\n",
        "Функция $SplitNode(m, R_m)$\n",
        "1. Если выполнен критерий остановки, то выход.\n",
        "2. Находим наилучший с точки зрения $Q$ предикат: $j, t$: $[x_j<t]$\n",
        "3. Помещаем предикат в вершину и получаем с его помощью разбиение $X$ на две части: $R_{left} = \\lbrace x|x_j<t \\rbrace$ и $R_{right} = \\lbrace x|x_j \\geqslant t \\rbrace$\n",
        "4. Поместим $R_{left}$ и $R_{right}$ соответсвенно в левое и правое поддерево.\n",
        "5. Рекурсивно повторяем $SplitNode(left, R_{left})$ и $SplitNode(right, R_{right})$.\n",
        "\n",
        "В конце поставим в соответствие каждому листу ответ. Для задачи классификации - это самый частый среди объектов класс или вектор с долями классов (можно интерпретировать как вероятности):\n",
        "$$ c_v = \\arg \\max_{k\\in Y} \\sum_{(x_i,y_i) \\in R_v} [y_i=k]  $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P6FsdBog4Ai"
      },
      "source": [
        "## Функционал качества для деревьев решений\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VAKO0aykGBD"
      },
      "source": [
        "Энтропия Шеннона для системы с N возможными состояниями определяется по формуле:\n",
        "$$H = - \\sum_{i=0}^{N} p_i\\log_2p_i $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5582B-1Fn2bw"
      },
      "source": [
        "где $p_i$ – вероятности нахождения системы в $i$-ом состоянии.\n",
        "\n",
        "Это очень важное понятие теории информации, которое позволяет оценить количество информации (степень хаоса в системе). Чем выше энтропия, тем менее упорядочена система и наоборот. С помощью энтропии мы формализуем функционал качества для разделение выборки (для задачи классификации)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PbcMUd7bvk05"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import random\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4AdLxP9CowTm"
      },
      "source": [
        "Код для расчёта энтропии:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2mT8Jq8Av2sM"
      },
      "outputs": [],
      "source": [
        "def entropy(y):\n",
        "\n",
        "    _, counts = np.unique(y, return_counts=True)\n",
        "\n",
        "    probabilities = counts / counts.sum()\n",
        "    entropy = sum(probabilities * -np.log2(probabilities))\n",
        "\n",
        "    return entropy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk9etb2vo7fK"
      },
      "source": [
        "Здесь $y$ - это массив значений целевой переменной"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07TCw0USzLus"
      },
      "source": [
        "Энтропия – по сути степень хаоса (или неопределенности) в системе. Уменьшение энтропии называют приростом информации (information gain, IG).\n",
        "\n",
        "Обочначим $R_v$ - объекты, которые нужно разделить в помощью предиката в вершине $v$. Запишем формулу для расчёта информационного прироста:\n",
        "$$ Q = IG = H(R_v) - (H(R_{left})+H(R_{right}))$$\n",
        "\n",
        "На каждом шаге нам нужно максимизировать этот функционал качества. Как это делать? Например, так можно перебрать $t$ для выбранного $j$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trEWHDoXg_p9"
      },
      "source": [
        "Предыдущая версия формулы прироста информации слишком упрощена. В работе необходимо использовать более устойчивую формулу, которая учитывает не только энтропию подмножеств, но и их размер.\n",
        "\n",
        "$$ Q = IG = H(R_v) - \\Big (\\frac{|R_{left}|} {|R_{v}|} H(R_{left})+ \\frac{|R_{right}|} {|R_{v}|} H(R_{right})\\Big)$$\n",
        "\n",
        "где, $|R_{v}|$, $|R_{left}|$ и $|R_{right}|$ - количество элементов в соответствующих множествах."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xmN6V_N1xBr"
      },
      "source": [
        "\n",
        "### Задание 4.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWFHZScF2CBF"
      },
      "source": [
        "Реализуйте алгоритм построения дерева. Должны быть отдельные функции (методы) для расчёта энтропии (уже есть), для разделения узлов дерева (используйте, например, `pandas`), для подсчёта функционала качества $IG$, для выбора наилучшего разделения (с учетом признаков и порогов), для проверки критерия остановки.\n",
        "\n",
        "Для набора данных `iris` реализуйте алгоритм и минимум три разных критерия остановки из перечисленных ниже:\n",
        "* максимальной глубины дерева = 5\n",
        "* минимального числа объектов в листе = 5\n",
        "* максимальное количество листьев в дереве = 5\n",
        "* purity (остановка, если все объекты в листе относятся к одному классу)\n",
        "\n",
        "Реализуйте функцию `predict` (на вход функции подаётся датафрейм с объектами)\n",
        "\n",
        "Оцените точность каждой модели с помощью метрики доля правильных ответов (`from sklearn.metrics import accuracy_score` или реализовать свою)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "OLtT2oqVk4bX"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "iris = datasets.load_iris()\n",
        "df = pd.DataFrame({'type': iris.target,\n",
        "                   'sepal length': iris.data[:,0],\n",
        "                   'sepal width': iris.data[:,1],\n",
        "                   'petal length': iris.data[:,2],\n",
        "                   'petal width': iris.data[:,3]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LK7hOyrQk-Za"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(df.drop(columns='type',axis=1), df.type)\n",
        "x_train.insert(0,'type',y_train)\n",
        "x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BVW2DHQpkSWa"
      },
      "outputs": [],
      "source": [
        "from numpy.core.fromnumeric import shape\n",
        "def findIG(l,r):#находит функционал качества для данного разделения\n",
        "  llen=len(l)\n",
        "  rlen=len(r)\n",
        "  lrlen=llen+rlen\n",
        "  lr=np.hstack((l,r))\n",
        "  #print(entropy(lr),entropy(l),entropy(r))\n",
        "  return (entropy(lr)-(llen/lrlen*entropy(l)+rlen/lrlen*entropy(r)))\n",
        "  #return (entropy(lr)-(entropy(l)+entropy(r)))\n",
        "\n",
        "def splitTree(df,numParts):#выбираем как лучше разделить наши данные на\n",
        "  feachure,maxIG,sep = 0,0,0 #на данное количество частей\n",
        "  L=pd.DataFrame()\n",
        "  R=pd.DataFrame()\n",
        "  for i in range(1,df.shape[1]):\n",
        "    col = df.columns[i]\n",
        "    x = np.linspace(min(df[col]),max(df[col]),numParts)\n",
        "    for j in x:\n",
        "      l=df.iloc[np.where(df[col]<j)]\n",
        "      r=df.iloc[np.where(df[col]>=j)]\n",
        "      if (findIG(l.iloc[:,0],r.iloc[:,0])>maxIG):\n",
        "        maxIG = findIG(l.iloc[:,0],r.iloc[:,0])\n",
        "        feachure = i\n",
        "        sep = j\n",
        "        L=l.copy()\n",
        "        R=r.copy()\n",
        "  return(feachure,sep,L,R)\n",
        "\n",
        "def isStop(deep,listObj,listCount,stopcrit):#проверка нужных критериев остановки\n",
        "  #print(stopcrit)\n",
        "  if stopcrit[0]==1 and deep==5:\n",
        "    return True\n",
        "  if stopcrit[1]==1 and listObj<=5:\n",
        "    return True\n",
        "  if stopcrit[2]==1 and listCount==5:\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "def maxProb(x):#выбирает самое частое значение\n",
        "  return x.value_counts().index[0]\n",
        "\n",
        "def makeTree(cur,tree,deep,df,listCount,numParts,stopcrit=[0,0,0]):# создает дерево рекурсивно\n",
        "  #print(tree.shape[0],tree)\n",
        "  if (not(isStop(deep,df.shape[0],listCount,stopcrit)) and entropy(df.iloc[:,0]))!=0:\n",
        "    #проверяем условия остановки\n",
        "    feach,sep,l,r=splitTree(df,numParts)# поделили дерево\n",
        "\n",
        "    tree[cur,0]=feach\n",
        "    tree[cur,1]=sep# заполнели информацию о делении в данную ветку\n",
        "    tree = np.vstack((tree,np.zeros((2,4))))\n",
        "    next = tree.shape[0]\n",
        "    tree[cur,2]=next-2\n",
        "    tree[cur,3]=next-1# заполнили информацию о потомках в текущую ветку\n",
        "    tree[next-2,0]=-1\n",
        "    tree[next-1,0]=-1\n",
        "    tree[next-2,1]=maxProb(l.iloc[:,0])#записали в потомках информацию на случай\n",
        "    tree[next-1,1]=maxProb(r.iloc[:,0])# если они останутся листами\n",
        "    tree1 = makeTree(next-2,tree,deep+1,l,listCount+1,numParts,stopcrit)\n",
        "    tree2 = makeTree(next-1,tree1,deep+1,r,listCount+1,numParts,stopcrit)\n",
        "\n",
        "    if (tree1.shape[0]>tree2.shape[0]):\n",
        "      tree = tree1.copy()\n",
        "      for i in range(tree2.shape[0]):\n",
        "        if tree2[i,2]!=0:\n",
        "          tree[i]=tree2[i]\n",
        "    else:\n",
        "      tree = tree2.copy()\n",
        "      for i in range(tree1.shape[0]):\n",
        "        if tree1[i,2]!=0:\n",
        "          tree[i]=tree1[i]\n",
        "# обновили информацию по поводу дерева\n",
        "  return tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qb7U4sRkrXc"
      },
      "source": [
        "[номер признака, значение признака, левый потомок, правый потомок]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RTdxLBVWlgok"
      },
      "outputs": [],
      "source": [
        "def pred(tree, x):\n",
        "  y = np.zeros(x.shape[0])\n",
        "  j=0\n",
        "  for i in x.values:\n",
        "    treeI=0\n",
        "    while tree[treeI,0]!=-1:\n",
        "      if i[int(tree[treeI,0])-1]>tree[treeI,1]:\n",
        "        treeI=tree[treeI,3]\n",
        "      else:\n",
        "        treeI=tree[treeI,2]\n",
        "      treeI=int(treeI)\n",
        "    y[j]=tree[treeI,1]\n",
        "    j+=1\n",
        "  return y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VyzzFFNOllUj"
      },
      "outputs": [],
      "source": [
        "# критерий остановки задаем массивом где 1 это использовать критерий, 0 - не использовать, чтобы мы могли комбинировать их\n",
        "tree = np.zeros((1,4))\n",
        "tree = makeTree(0,tree,1,x_train,1,30,[0,0,0]) #критерий остановки только пьюрити\n",
        "p = pred(tree,x_test)\n",
        "print(accuracy_score(y_test,p))\n",
        "print(tree)\n",
        "\n",
        "tree = np.zeros((1,4))\n",
        "tree = makeTree(0,tree,1,x_train,1,30,[0,0,1])#останавливаемся при глубине = 5\n",
        "p = pred(tree,x_test)\n",
        "print(accuracy_score(y_test,p))\n",
        "print(tree)\n",
        "\n",
        "tree = np.zeros((1,4))\n",
        "tree = makeTree(0,tree,1,x_train,1,30,[0,1,0])#останавливаемся при колличестве элементов в листе 5 или меньше\n",
        "p = pred(tree,x_test)\n",
        "print(accuracy_score(y_test,p))\n",
        "print(tree)\n",
        "\n",
        "tree = np.zeros((1,4))\n",
        "tree = makeTree(0,tree,1,x_train,1,30,[1,0,0])#останавливаемся при колличестве листьев = 5\n",
        "p = pred(tree,x_test)\n",
        "print(accuracy_score(y_test,p))\n",
        "print(tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "H-mCuHHPlpjW"
      },
      "outputs": [],
      "source": [
        "plt.scatter(df.iloc[:50,3],df.iloc[:50,4])# визуализация данных\n",
        "plt.scatter(df.iloc[50:100,3],df.iloc[50:100,4])\n",
        "plt.scatter(df.iloc[100:150,3],df.iloc[100:150,4])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFy2gySilqRw"
      },
      "source": [
        "С каждым из критериев остановки точность дерева больше, чем только с purity, но сами резудьтаты вышли одинаковыми, что связано с небольшим колличеством данных, и довольно схожими начальными разделениями, но можно заметить что дял остановки по глубине или по колличеству листьев, при той же точности, само дерево короче\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BkyCjLcy_CTM"
      },
      "source": [
        "##  Случайный лес"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fKZe1FyRgCa"
      },
      "source": [
        "Опишем алгоритм случайный лес (*random forest*) и попутно разберём основные идеи:\n",
        "\n",
        "1. Зададим $N$ - число деревьев в лесу.\n",
        "2. Для каждого $n$ из $N$ сгенерируем свою выборку $X_n$. Пусть $m$ - это количество объектов в $X$. При генерации каждой $X_n$ мы будем брать объекты $m$ раз с возвращением. То есть один и тот же объект может попасть в выборку несколько раз, а какие-то объекты не попадут. (Этот способ назвается бутстрап).\n",
        "3. По каждой $X_n$ построим решающее дерево $b_n$. Обычно стараются делать глубокие деревья. В качестве критериев остановки можно использовать `max_depth` или `min_samples_leaf` (например, пока в каждом листе не окажется по одному объекту). При каждом разбиении сначала выбирается $k$ (эвристика $k = \\sqrt d$, где $d$ - это число признаков объектов из выборки $X$) случайных признаков из исходных, и оптимальное разделение выборки ищется только среди них. Обратите внимание, что мы не выбрасываем оставшиеся признаки!\n",
        "4. Итоговый алгоритм будет представлять собой результат голосования (для классификации) и среднее арифметическое (для регрессии). Модификация алгоритма предполагает учёт весов каждого отдельного слабого алгоритма в ансамбле, но в этом особо нет смысла.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJBQ8lc0WyrN"
      },
      "source": [
        "### Задание 4.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y594Jn04ZTCm"
      },
      "source": [
        "В качестве набора данных используйте: https://www.kaggle.com/mathchi/churn-for-bank-customers\n",
        "\n",
        "Там есть описание и примеры работы с этими данными. Если кратко, речь идёт про задачу прогнозирования оттока клиентов. Есть данные о 10 тысячах клиентов банка, часть из которых больше не являются клиентами."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be_mLbdVW2oG"
      },
      "source": [
        "Используя либо свою реализацию, либо  `DecisionTreeClassifier` с разными настройками из `sklearn.tree` реализйте алгоритм \"случайный лес\".\n",
        "\n",
        "Найдите наилучшие гиперпараметры этого алгоритма: количество деревьев, критерий остановки, функционал качества, минимальное количество объектов в листьях и другие.\n",
        "\n",
        "Нельзя использовать готовую реализацию случайного леса из `sklearn`.\n",
        "\n",
        "В подобных задачах очень важна интерпретируемость алгоритма. Попытайтесь оценить информативность признаков, т.е. ответить а вопрос, значения каких признаков являются самыми важными индикаторами того, что банк потеряет клиента."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "01eACrMymzH0"
      },
      "outputs": [],
      "source": [
        "!gdown 1F5Vh-TTLqD9lqJ9deHlXJKIkyvTuE5wR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TSX_nVtvmzwd"
      },
      "outputs": [],
      "source": [
        "from numpy.lib.function_base import append\n",
        "df = pd.read_csv(filepath_or_buffer = \"churn.csv\")\n",
        "df = df.drop(['RowNumber','CustomerId','Surname'], axis=1)#удаляю так как сама инструкция к датабазе выделяет эти поля как неважные\n",
        "df.Gender = np.where(df.Gender == 'Male', 0, df.Gender)\n",
        "df.Gender = np.where(df.Gender == 'Female', 1, df.Gender)\n",
        "df['isFrance']=df.Geography.apply(lambda x: 1 if x==\"France\" else 0)\n",
        "df['isSpain']=df.Geography.apply(lambda x: 1 if x==\"Spain\" else 0)\n",
        "df['isGermany']=df.Geography.apply(lambda x: 1 if x==\"Germany\" else 0)\n",
        "df=df.drop(columns = ['Geography'],axis = 1)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SIAxixtXm7bX"
      },
      "outputs": [],
      "source": [
        "data=df.drop(['Exited'], axis=1)\n",
        "target=df.Exited.to_frame()\n",
        "data\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def makeData(x,y):\n",
        "  l=len(y)\n",
        "  x['Exited']=y\n",
        "  x=shuffle(x)         #если мы каждый раз будем полностью рандомить все строчки, для построения леса у нас будет уходить слишком много времени\n",
        "  proc = round(l*0.3)  #а нам понадобится его строить помногу раз чтобы подобрать лучшие гиперпараметры\n",
        "  x = x.iloc[proc:,:]  #поэтому мы перемешиваем строки, удаляем примерно треть, и копируем столькоже\n",
        "  x = pd.concat([x.iloc[proc:, :], x.iloc[0:proc, :]], ignore_index=True) # это примерно то же самое что рандомно брать все строки\n",
        "  rx=x.drop(['Exited'], axis=1)\n",
        "  ry=x.Exited.to_frame()\n",
        "  return rx,ry\n",
        "\n",
        "def trainForest(x,y,numTrees, min_samples_leaf=1, depth=None, min_impurity_decrease=0):\n",
        "  clf=[]\n",
        "  for i in range(numTrees):\n",
        "    clf.append(tree.DecisionTreeClassifier(max_depth = depth,\\\n",
        "                                           max_features = 'sqrt',\\\n",
        "                                           min_samples_leaf=min_samples_leaf,\\\n",
        "                                           min_impurity_decrease=min_impurity_decrease))\n",
        "    rx,ry=makeData(x,y)\n",
        "    clf[i]=clf[i].fit(rx,ry)\n",
        "  return clf\n",
        "\n",
        "def predict(trees, x):\n",
        "  y=np.zeros(len(x))\n",
        "  for i in trees:\n",
        "    y=y+i.predict(x)\n",
        "  y=y//((len(trees)//2)+1)\n",
        "  return y\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, target)\n",
        "\n",
        "maxi = 0\n",
        "n,m,d,i=0,0,0,0\n",
        "minSamp = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ph67aF_yqgu7"
      },
      "outputs": [],
      "source": [
        "#здесь мы перебираем деревья чтобы найти лучшее(закоментировано, так как заняло много времени)\n",
        "\n",
        "# for numTree in range(10,101,10):\n",
        "#     print(numTree, minSamp)\n",
        "#     print(maxi,n,m,d,i)\n",
        "#     for dep in range(5,51,5):\n",
        "#       x = np.linspace(0.0001,0.001,10)\n",
        "#       for imp in x:\n",
        "#         clf = trainForest(x_train,y_train,numTree,minSamp,dep,imp)\n",
        "#         proc = (predict(clf,x_test).reshape(1,-1) == y_test.values.reshape(1,-1))\n",
        "#         if(sum(sum(proc))/2500*100>maxi):\n",
        "#           maxi=sum(sum(proc))/2500*100\n",
        "#           n=numTree\n",
        "#           m=minSamp\n",
        "#           d=dep\n",
        "#           i=imp\n",
        "\n",
        "# print(n,m,d,i)\n",
        "\n",
        "print(30, 1, 10, 0.0001) #результат и лучшие пораметры судя по перебору"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7WIPJnEpRJ5"
      },
      "source": [
        "по итогу перебора вышло: \\\\\n",
        "лучшее колличество деревьев - 30 \\\\\n",
        "минимальное количество листьев в дереве - 1 \\\\\n",
        "максимальная глубина дерева - 10 \\\\\n",
        "минимальное изменение функционала качества 0.0001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qYNucmTUpQz0"
      },
      "outputs": [],
      "source": [
        "mi=100\n",
        "ma=0\n",
        "for i in range (10):\n",
        "  t = trainForest(x_train,y_train,30, 1, 10, 0.0001)\n",
        "  proc = (predict(t,x_test).reshape(1,-1) == y_test.values.reshape(1,-1))\n",
        "  mi=min(mi,sum(sum(proc))/2500*100)\n",
        "  if (ma<sum(sum(proc))/2500*100):\n",
        "    ma=sum(sum(proc))/2500*100\n",
        "    bestTree = t\n",
        " #худший и лучший результат леса с данными параметрами за 10 прогонов\n",
        "mi,ma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yiKL_c8spaQw"
      },
      "outputs": [],
      "source": [
        "bestTree[0].feature_importances_# показывает важность фич в дереве, найдем среднее по всем деревьям в лесу\n",
        "\n",
        "topF=np.zeros_like(bestTree[0].feature_importances_)\n",
        "l=len(bestTree)\n",
        "for i in range(l):\n",
        "  topF+=bestTree[i].feature_importances_\n",
        "print(topF/l)\n",
        "\n",
        "attributes = pd.DataFrame(data = {'Attribute': data.columns,'Importance' : topF/l}).sort_values(by = 'Importance', ascending = False).head()\n",
        "attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bU8d63onprCt"
      },
      "source": [
        "Мы видем что самым важным пораметром оказался второй(с нуля), что не удевительно, так как это возраст клиента, так же к сильно значемым пораметрам можно отнести 5 и 4 (в этом порядке), а это количество продуктов купленных у банка и баланс соответственно, по большей части именно эти три категории дают нам понять останется ли клиент у банка. Соответственно небольшой возраст, отсутствие купленых продуктов банка и небольшой баланс в банке является индекатором того, что клиент скорее всего покинет банк."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}